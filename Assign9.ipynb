{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7abc5fdf-6df9-46e4-9c97-692afcd6f4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "technology has revolutionized the way we live from smartphones to artificial intelligence it has impacted every aspect of our lives i love exploring new gadgets and learning how they work the future of technology looks promising with advancements in robotics machine learning and virtual reality its exciting to imagine the innovations that await us\n"
     ]
    }
   ],
   "source": [
    "# Q1. Write a unique paragraph (5-6 sentences) about your favorite topic (e.g., sports,\n",
    "# technology, food, books, etc.).\n",
    "# 1. Convert text to lowercase and remove punctuaƟon.\n",
    "import re\n",
    "paragraph = \"Technology has revolutionized the way we live. From smartphones to artificial intelligence, it has impacted every aspect of our lives. I love exploring new gadgets and learning how they work. The future of technology looks promising with advancements in robotics, machine learning, and virtual reality. It’s exciting to imagine the innovations that await us!\"\n",
    "#i)\n",
    "#converting to lowercase\n",
    "text = paragraph.lower()\n",
    "#remoivng punctuation\n",
    "text = re.sub(r'[^\\w\\s]', '' , text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16fa3928-b11e-424e-b2ee-1635a4bee15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (4.66.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d70dcbc-9b89-43e4-bd6d-ae41e6f2e8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/parth/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "964b1882-314e-4d1c-aaa5-bf326fa66524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /Users/parth/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4e2f221-70f8-41f8-809d-9b2051c089fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences: ['technology has revolutionized the way we live from smartphones to artificial intelligence it has impacted every aspect of our lives i love exploring new gadgets and learning how they work the future of technology looks promising with advancements in robotics machine learning and virtual reality its exciting to imagine the innovations that await us']\n",
      "words: ['technology', 'has', 'revolutionized', 'the', 'way', 'we', 'live', 'from', 'smartphones', 'to', 'artificial', 'intelligence', 'it', 'has', 'impacted', 'every', 'aspect', 'of', 'our', 'lives', 'i', 'love', 'exploring', 'new', 'gadgets', 'and', 'learning', 'how', 'they', 'work', 'the', 'future', 'of', 'technology', 'looks', 'promising', 'with', 'advancements', 'in', 'robotics', 'machine', 'learning', 'and', 'virtual', 'reality', 'its', 'exciting', 'to', 'imagine', 'the', 'innovations', 'that', 'await', 'us']\n"
     ]
    }
   ],
   "source": [
    "# 2. Tokenize the text into words and sentences.\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "sentences = sent_tokenize(text)\n",
    "words = word_tokenize(text)\n",
    "print(\"sentences:\" ,sentences )\n",
    "print(\"words:\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c45f5cf8-862d-4e5f-96e2-00ee09c850cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/parth/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Remove stopwords (using NLTK's stopwords list).\n",
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca8c67ab-7a06-4925-b172-091c65dd108a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['technology', 'revolutionized', 'way', 'live', 'smartphones', 'artificial', 'intelligence', 'impacted', 'every', 'aspect', 'lives', 'love', 'exploring', 'new', 'gadgets', 'learning', 'work', 'future', 'technology', 'looks', 'promising', 'advancements', 'robotics', 'machine', 'learning', 'virtual', 'reality', 'exciting', 'imagine', 'innovations', 'await', 'us']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = []\n",
    "for word in words:\n",
    "    if word not in stop_words:\n",
    "        filtered_words.append(word)\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bee3516-c6d3-42d5-8d9a-2590b4b1b7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 30 samples and 32 outcomes>\n"
     ]
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "freq_dist = FreqDist(filtered_words)\n",
    "print(freq_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06099728-4f50-4b93-b1c7-3044fd75e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Tokenized words after stopword removal from Q1\n",
    "filtered_words = ['technology', 'revolutionized', 'way', 'live', 'work', 'communicate', 'smartphones', 'artificial', 'intelligence', 'advancements', 'technology', 'made', 'lives', 'convenient', 'efficient', 'opened', 'new', 'opportunities', 'innovation', 'creativity', 'enabling', 'us', 'solve', 'complex', 'problems', 'improve', 'quality', 'life', 'however', 'also', 'comes', 'challenges', 'privacy', 'concerns', 'need', 'ethical', 'considerations', 'technology', 'continues', 'evolve', 'crucial', 'strike', 'balance', 'progress', 'responsibility', 'ensure', 'sustainable', 'future']\n",
    "\n",
    "# Initialize stemmers and lemmatizer\n",
    "porter_stemmer = PorterStemmer()\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Apply stemming\n",
    "porter_stemmed = [porter_stemmer.stem(word) for word in filtered_words]\n",
    "lancaster_stemmed = [lancaster_stemmer.stem(word) for word in filtered_words]\n",
    "\n",
    "# Apply lemmatization\n",
    "lemmatized = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "\n",
    "# Display comparison\n",
    "for i, word in enumerate(filtered_words[:10]):  # Display first 10 words for brevity\n",
    "    print(f\"Original: {word}\")\n",
    "    print(f\"Porter Stemming: {porter_stemmed[i]}\")\n",
    "    print(f\"Lancaster Stemming: {lancaster_stemmed[i]}\")\n",
    "    print(f\"Lemmatization: {lemmatized[i]}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d080216d-ea6e-4080-81b8-a378feeccb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Original text from Question 1\n",
    "original_text = \"Technology has revolutionized the way we live, work, and communicate. From smartphones to artificial intelligence, advancements in technology have made our lives more convenient and efficient. It has opened up new opportunities for innovation and creativity, enabling us to solve complex problems and improve our quality of life. However, it also comes with challenges such as privacy concerns and the need for ethical considerations. As technology continues to evolve, it is crucial to strike a balance between progress and responsibility to ensure a sustainable future.\"\n",
    "\n",
    "print(\"Original Text:\")\n",
    "print(original_text)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 2a. Extract all words with more than 5 letters\n",
    "words_more_than_5 = re.findall(r'\\b\\w{6,}\\b', original_text)\n",
    "print(\"Words with more than 5 letters:\")\n",
    "print(words_more_than_5)\n",
    "print(f\"Total count: {len(words_more_than_5)}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# 2b. Extract all numbers (if any exist in the text)\n",
    "numbers_in_text = re.findall(r'\\b\\d+\\b', original_text)\n",
    "print(\"Numbers in the text:\")\n",
    "print(numbers_in_text if numbers_in_text else \"No numbers found in the text\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# 2c. Extract all capitalized words\n",
    "capitalized_words = re.findall(r'\\b[A-Z][a-z]*\\b', original_text)\n",
    "print(\"Capitalized words:\")\n",
    "print(capitalized_words)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 3a. Split the text into words containing only alphabets\n",
    "alphabetic_words = re.findall(r'\\b[a-zA-Z]+\\b', original_text)\n",
    "print(\"Words containing only alphabets:\")\n",
    "print(alphabetic_words)\n",
    "print(f\"Total count: {len(alphabetic_words)}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# 3b. Extract words starting with a vowel\n",
    "vowel_words = [word for word in alphabetic_words if word.lower()[0] in 'aeiou']\n",
    "print(\"Words starting with a vowel:\")\n",
    "print(vowel_words)\n",
    "print(f\"Total count: {len(vowel_words)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6f0f3d-3bdb-4193-89ce-687bd57b1b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "# Original text from Question 1\n",
    "original_text = \"Technology has revolutionized the way we live, work, and communicate. From smartphones to artificial intelligence, advancements in technology have made our lives more convenient and efficient. It has opened up new opportunities for innovation and creativity, enabling us to solve complex problems and improve our quality of life. However, it also comes with challenges such as privacy concerns and the need for ethical considerations. As technology continues to evolve, it is crucial to strike a balance between progress and responsibility to ensure a sustainable future.\"\n",
    "\n",
    "# Add some test cases with contractions, hyphenated words, and numbers\n",
    "test_text = original_text + \" The state-of-the-art AI isn't just about efficiency—it's about creating a better world with 3.14 times more innovation. Contact us at info@tech-future.com or visit https://tech-innovation.org. Call us at 123-456-7890 or +91 9876543210.\"\n",
    "\n",
    "def custom_tokenizer(text):\n",
    "    # First, protect contractions by replacing apostrophes with a special marker\n",
    "    text = re.sub(r\"(\\w+)'(\\w+)\", r\"\\1_APOS_\\2\", text)\n",
    "\n",
    "    # Protect hyphenated words\n",
    "    text = re.sub(r\"(\\w+)-(\\w+)(-(\\w+))*\", lambda m: m.group(0).replace('-', '_HYPHEN_'), text)\n",
    "\n",
    "    # Protect decimal numbers\n",
    "    text = re.sub(r\"(\\d+)\\.(\\d+)\", r\"\\1_DOT_\\2\", text)\n",
    "\n",
    "    # Remove other punctuation and special symbols\n",
    "    text = re.sub(r\"[^\\w\\s]\", ' ', text)\n",
    "\n",
    "    # Split into tokens\n",
    "    tokens = text.split()\n",
    "\n",
    "    # Restore protected elements\n",
    "    tokens = [token.replace('_APOS_', \"'\").replace('_HYPHEN_', '-').replace('_DOT_', '.') for token in tokens]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def replace_placeholders(text):\n",
    "    # Replace email addresses with \n",
    "    text = re.sub(r'[\\w.-]+@[\\w.-]+\\.\\w+', '', text)\n",
    "\n",
    "    # Replace URLs with \n",
    "    text = re.sub(r'https?://[\\w.-]+(?:\\.\\w+)+(?:/[\\w.-]*)*', '', text)\n",
    "\n",
    "    # Replace phone numbers with \n",
    "    text = re.sub(r'(?:\\+\\d{1,3}[ -]?)?\\d{3}[ -]?\\d{3}[ -]?\\d{4}|\\+\\d{1,3}\\s\\d{10}', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Test the custom tokenizer\n",
    "tokens = custom_tokenizer(test_text)\n",
    "print(\"Custom Tokenization Results:\")\n",
    "print(tokens)\n",
    "print(f\"Number of tokens: {len(tokens)}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Test the placeholder replacements\n",
    "cleaned_text = replace_placeholders(test_text)\n",
    "print(\"Text with Placeholders:\")\n",
    "print(cleaned_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
